##ğŸ¦Š KURAMA

Enterprise-Grade Hybrid AI Assistant
Built with DevOps principles. Designed for intelligence, reliability, and control.

Inspired by the Nine-Tailed Fox â€” powerful, controlled, and engineered.

#ğŸ§  Overview

KURAMA is a modular hybrid AI assistant framework designed with production-grade architecture and DevOps best practices.

It combines:

```bash
ğŸ§  Local-first AI processing using Ollama  
ğŸ” Secure system command orchestration  
ğŸŒ REST API interface (FastAPI)  
ğŸ“¦ Containerized deployment  
ğŸ” CI/CD-ready architecture  
â˜ï¸ Extensible cloud intelligence (future support for providers like OpenAI) 
```
KURAMA is not just a chatbot â€” it is an AI system engineered with infrastructure discipline.

ğŸ— Architecture

KURAMA follows a modular layered architecture:

```bash
User Input
    â†“
Intent Classification Layer
    â†“
Decision Engine (Routing)
   â†™                     â†˜
Local LLM             Command Executor
(Ollama)              (Validated & Secure)
    â†“
Response Formatter
    â†“
API Output
```

Design Principles

```bash
ğŸ” Security-first command validation
ğŸ§  Intent-driven routing logic
âš™ï¸ Modular service separation
ğŸ“¦ Containerized runtime
ğŸ“Š Observability-ready structure
â˜ï¸ Hybrid-ready (Local + Cloud extensibility)
```

ğŸ“ Project Structure

```bash
kurama/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ chakra_engine.py
â”‚   â”œâ”€â”€ sharingan.py
â”‚   â””â”€â”€ memory.py
â”‚
â”œâ”€â”€ llm/
â”‚   â””â”€â”€ ollama_client.py
â”‚
â”œâ”€â”€ commands/
â”‚   â”œâ”€â”€ executor.py
â”‚   â””â”€â”€ allowed_commands.py
â”‚
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ logger.py
â”‚
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml
```
## âš™ï¸ Core Capabilities (Phase 1)

```bash
ğŸ§  Local LLM inference via Ollama  
ğŸ” Secure system command execution layer  
ğŸŒ FastAPI REST interface  
ğŸ“¦ Dockerized deployment  
ğŸ” CI pipeline integration  
ğŸ— Structured modular backend  
```
